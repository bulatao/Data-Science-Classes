{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images and Classifiers for Devanagari digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the following dataset:\n",
    "# https://archive.ics.uci.edu/ml/datasets/Devanagari+Handwritten+Character+Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read images from Train/digit_X; convert to gray-scale values; attach label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ...\n",
    "# train about 100 images per digit\n",
    "# afterwards, you can increase it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install tensorflow through anaconda navigator\n",
    "# installing cv2\n",
    "# pip install opencv-python\n",
    "# this had to be done from the anaconda prompt\n",
    "# use tutorial for cats and dogs https://www.youtube.com/watch?v=j-3vuBynnOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read images from Train/digit_X\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR = \"C:/Users/bulatao/Documents/GitHub/Data-Science-Classes/DevanagariHandwrittenCharacterDataset/Train\"\n",
    "\n",
    "CATEGORIES = [\"digit_0\", \"digit_1\",\"digit_2\",\"digit_3\",\"digit_4\",\"digit_5\",\"digit_6\",\"digit_7\",\"digit_8\",\"digit_9\"]\n",
    "\n",
    "for category in CATEGORIES:  # 0 through 9\n",
    "    path = os.path.join(DATADIR,category)  # create path to folders with samples\n",
    "    for img in os.listdir(path):  # iterate over each image \n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show()  # display!\n",
    "\n",
    "        break  # we just want one for now so break\n",
    "    break  #...and one more!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array) # let's see what this looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 480.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 508.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 527.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 505.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 490.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 494.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 507.02it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 519.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 507.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1700/1700 [00:03<00:00, 520.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000\n"
     ]
    }
   ],
   "source": [
    "# read images and add labels and create complete dataset\n",
    "\n",
    "training_data = []\n",
    "\n",
    "IMG_SIZE = 32\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # for digits 0 to 9\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0 = digit_0, 1 = digit_1\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "5\n",
      "1\n",
      "4\n",
      "3\n",
      "4\n",
      "9\n",
      "8\n",
      "4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import random # this didn't seem to affect accuracy too much, but was recommended\n",
    "\n",
    "random.shuffle(training_data)\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Training Data and Labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "#print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1)) \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X[1] # check what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 32, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read images from Test/digit_X; convert to gray-scale values; attach label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 483.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 517.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 535.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 521.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 518.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 506.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 519.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 508.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 514.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 536.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Your code here ...\n",
    "# read test images same way we did training images\n",
    "\n",
    "test_data = []\n",
    "\n",
    "def create_test_data():\n",
    "    for category in CATEGORIES:  # for digits 0 to 9\n",
    "\n",
    "        path = os.path.join(\"C:/Users/bulatao/Documents/GitHub/Data-Science-Classes/DevanagariHandwrittenCharacterDataset/Test\",category)  # create path to dogs and cats\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0 = digit_0, 1 = digit_1\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                #new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                test_data.append([img_array, class_num])  # add this to our test_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))\n",
    "\n",
    "create_test_data()\n",
    "\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "9\n",
      "9\n",
      "7\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# shuffle test data\n",
    "random.shuffle(test_data)\n",
    "for sample in test_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Data and Labels\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for features,label in test_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "\n",
    "#print(X_test[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1)) \n",
    "\n",
    "X_test = np.array(X_test) # change from list to np array\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the classifiers using steps from MNIST classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here ...\n",
    "# Here's a TensorFlow image classifier with Keras\n",
    "# https://pythonprogramming.net/convolutional-neural-network-deep-learning-python-tensorflow-keras/\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "tf.enable_eager_execution() # this is necessary later when trying to pickle this model\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's normalize the data\n",
    "# this portion here made a huge difference in accuracy\n",
    "X = tf.keras.utils.normalize(X, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # we'll need this later to save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "17000/17000 [==============================] - ETA: 4:25 - loss: 2.3229 - acc: 0.0000e+0 - ETA: 26s - loss: 2.0867 - acc: 0.3580    - ETA: 16s - loss: 1.8538 - acc: 0.48 - ETA: 11s - loss: 1.6016 - acc: 0.57 - ETA: 9s - loss: 1.3681 - acc: 0.6343 - ETA: 8s - loss: 1.2637 - acc: 0.658 - ETA: 8s - loss: 1.1770 - acc: 0.679 - ETA: 7s - loss: 1.0689 - acc: 0.703 - ETA: 6s - loss: 0.9909 - acc: 0.723 - ETA: 6s - loss: 0.9452 - acc: 0.733 - ETA: 5s - loss: 0.8804 - acc: 0.751 - ETA: 5s - loss: 0.8372 - acc: 0.762 - ETA: 5s - loss: 0.8011 - acc: 0.771 - ETA: 4s - loss: 0.7568 - acc: 0.784 - ETA: 4s - loss: 0.7207 - acc: 0.794 - ETA: 4s - loss: 0.6930 - acc: 0.800 - ETA: 4s - loss: 0.6598 - acc: 0.809 - ETA: 3s - loss: 0.6359 - acc: 0.816 - ETA: 3s - loss: 0.6150 - acc: 0.822 - ETA: 3s - loss: 0.5949 - acc: 0.827 - ETA: 3s - loss: 0.5731 - acc: 0.833 - ETA: 3s - loss: 0.5623 - acc: 0.835 - ETA: 3s - loss: 0.5501 - acc: 0.839 - ETA: 3s - loss: 0.5327 - acc: 0.844 - ETA: 2s - loss: 0.5176 - acc: 0.848 - ETA: 2s - loss: 0.5093 - acc: 0.850 - ETA: 2s - loss: 0.4973 - acc: 0.853 - ETA: 2s - loss: 0.4881 - acc: 0.855 - ETA: 2s - loss: 0.4796 - acc: 0.857 - ETA: 2s - loss: 0.4707 - acc: 0.860 - ETA: 2s - loss: 0.4657 - acc: 0.861 - ETA: 2s - loss: 0.4614 - acc: 0.862 - ETA: 2s - loss: 0.4550 - acc: 0.864 - ETA: 2s - loss: 0.4467 - acc: 0.866 - ETA: 2s - loss: 0.4395 - acc: 0.868 - ETA: 2s - loss: 0.4351 - acc: 0.869 - ETA: 1s - loss: 0.4319 - acc: 0.871 - ETA: 1s - loss: 0.4250 - acc: 0.872 - ETA: 1s - loss: 0.4191 - acc: 0.874 - ETA: 1s - loss: 0.4136 - acc: 0.876 - ETA: 1s - loss: 0.4091 - acc: 0.877 - ETA: 1s - loss: 0.4050 - acc: 0.878 - ETA: 1s - loss: 0.4010 - acc: 0.879 - ETA: 1s - loss: 0.3944 - acc: 0.881 - ETA: 1s - loss: 0.3892 - acc: 0.883 - ETA: 1s - loss: 0.3849 - acc: 0.884 - ETA: 1s - loss: 0.3778 - acc: 0.886 - ETA: 1s - loss: 0.3744 - acc: 0.888 - ETA: 1s - loss: 0.3706 - acc: 0.889 - ETA: 1s - loss: 0.3654 - acc: 0.890 - ETA: 0s - loss: 0.3626 - acc: 0.891 - ETA: 0s - loss: 0.3579 - acc: 0.892 - ETA: 0s - loss: 0.3539 - acc: 0.893 - ETA: 0s - loss: 0.3500 - acc: 0.894 - ETA: 0s - loss: 0.3472 - acc: 0.895 - ETA: 0s - loss: 0.3437 - acc: 0.896 - ETA: 0s - loss: 0.3399 - acc: 0.897 - ETA: 0s - loss: 0.3367 - acc: 0.898 - ETA: 0s - loss: 0.3346 - acc: 0.898 - ETA: 0s - loss: 0.3325 - acc: 0.899 - ETA: 0s - loss: 0.3311 - acc: 0.899 - ETA: 0s - loss: 0.3294 - acc: 0.900 - ETA: 0s - loss: 0.3277 - acc: 0.900 - ETA: 0s - loss: 0.3254 - acc: 0.901 - ETA: 0s - loss: 0.3240 - acc: 0.901 - ETA: 0s - loss: 0.3221 - acc: 0.902 - ETA: 0s - loss: 0.3205 - acc: 0.902 - ETA: 0s - loss: 0.3186 - acc: 0.903 - 4s 241us/sample - loss: 0.3167 - acc: 0.9038\n",
      "Epoch 2/5\n",
      "17000/17000 [==============================] - ETA: 4s - loss: 0.1663 - acc: 0.968 - ETA: 3s - loss: 0.1830 - acc: 0.944 - ETA: 3s - loss: 0.1734 - acc: 0.942 - ETA: 3s - loss: 0.1762 - acc: 0.943 - ETA: 3s - loss: 0.1659 - acc: 0.947 - ETA: 3s - loss: 0.1565 - acc: 0.951 - ETA: 3s - loss: 0.1516 - acc: 0.952 - ETA: 3s - loss: 0.1476 - acc: 0.954 - ETA: 3s - loss: 0.1428 - acc: 0.955 - ETA: 3s - loss: 0.1395 - acc: 0.957 - ETA: 3s - loss: 0.1379 - acc: 0.958 - ETA: 3s - loss: 0.1321 - acc: 0.960 - ETA: 3s - loss: 0.1324 - acc: 0.961 - ETA: 2s - loss: 0.1293 - acc: 0.962 - ETA: 2s - loss: 0.1297 - acc: 0.961 - ETA: 2s - loss: 0.1247 - acc: 0.963 - ETA: 2s - loss: 0.1245 - acc: 0.962 - ETA: 2s - loss: 0.1241 - acc: 0.962 - ETA: 2s - loss: 0.1223 - acc: 0.963 - ETA: 2s - loss: 0.1209 - acc: 0.963 - ETA: 2s - loss: 0.1187 - acc: 0.963 - ETA: 2s - loss: 0.1176 - acc: 0.963 - ETA: 2s - loss: 0.1171 - acc: 0.963 - ETA: 2s - loss: 0.1192 - acc: 0.963 - ETA: 2s - loss: 0.1222 - acc: 0.962 - ETA: 1s - loss: 0.1202 - acc: 0.962 - ETA: 1s - loss: 0.1186 - acc: 0.963 - ETA: 1s - loss: 0.1184 - acc: 0.963 - ETA: 1s - loss: 0.1196 - acc: 0.963 - ETA: 1s - loss: 0.1201 - acc: 0.963 - ETA: 1s - loss: 0.1206 - acc: 0.963 - ETA: 1s - loss: 0.1193 - acc: 0.963 - ETA: 1s - loss: 0.1180 - acc: 0.964 - ETA: 1s - loss: 0.1168 - acc: 0.964 - ETA: 1s - loss: 0.1163 - acc: 0.964 - ETA: 1s - loss: 0.1147 - acc: 0.965 - ETA: 1s - loss: 0.1143 - acc: 0.965 - ETA: 1s - loss: 0.1147 - acc: 0.964 - ETA: 1s - loss: 0.1144 - acc: 0.964 - ETA: 1s - loss: 0.1146 - acc: 0.964 - ETA: 1s - loss: 0.1150 - acc: 0.964 - ETA: 1s - loss: 0.1158 - acc: 0.964 - ETA: 1s - loss: 0.1153 - acc: 0.964 - ETA: 0s - loss: 0.1147 - acc: 0.964 - ETA: 0s - loss: 0.1134 - acc: 0.965 - ETA: 0s - loss: 0.1133 - acc: 0.965 - ETA: 0s - loss: 0.1124 - acc: 0.965 - ETA: 0s - loss: 0.1117 - acc: 0.965 - ETA: 0s - loss: 0.1118 - acc: 0.966 - ETA: 0s - loss: 0.1109 - acc: 0.966 - ETA: 0s - loss: 0.1103 - acc: 0.966 - ETA: 0s - loss: 0.1101 - acc: 0.966 - ETA: 0s - loss: 0.1102 - acc: 0.966 - ETA: 0s - loss: 0.1097 - acc: 0.966 - ETA: 0s - loss: 0.1096 - acc: 0.966 - ETA: 0s - loss: 0.1096 - acc: 0.966 - ETA: 0s - loss: 0.1097 - acc: 0.966 - ETA: 0s - loss: 0.1093 - acc: 0.966 - ETA: 0s - loss: 0.1089 - acc: 0.966 - ETA: 0s - loss: 0.1088 - acc: 0.966 - ETA: 0s - loss: 0.1087 - acc: 0.966 - 3s 185us/sample - loss: 0.1086 - acc: 0.9665\n",
      "Epoch 3/5\n",
      "17000/17000 [==============================] - ETA: 5s - loss: 0.0641 - acc: 1.000 - ETA: 3s - loss: 0.0917 - acc: 0.972 - ETA: 3s - loss: 0.0857 - acc: 0.972 - ETA: 2s - loss: 0.0753 - acc: 0.977 - ETA: 3s - loss: 0.0757 - acc: 0.975 - ETA: 2s - loss: 0.0669 - acc: 0.980 - ETA: 2s - loss: 0.0667 - acc: 0.981 - ETA: 2s - loss: 0.0663 - acc: 0.982 - ETA: 2s - loss: 0.0627 - acc: 0.982 - ETA: 2s - loss: 0.0605 - acc: 0.982 - ETA: 2s - loss: 0.0585 - acc: 0.982 - ETA: 2s - loss: 0.0617 - acc: 0.981 - ETA: 2s - loss: 0.0602 - acc: 0.982 - ETA: 2s - loss: 0.0610 - acc: 0.981 - ETA: 2s - loss: 0.0612 - acc: 0.981 - ETA: 2s - loss: 0.0594 - acc: 0.981 - ETA: 2s - loss: 0.0602 - acc: 0.981 - ETA: 2s - loss: 0.0634 - acc: 0.981 - ETA: 2s - loss: 0.0640 - acc: 0.981 - ETA: 2s - loss: 0.0657 - acc: 0.980 - ETA: 1s - loss: 0.0655 - acc: 0.980 - ETA: 1s - loss: 0.0649 - acc: 0.980 - ETA: 1s - loss: 0.0643 - acc: 0.981 - ETA: 1s - loss: 0.0641 - acc: 0.981 - ETA: 1s - loss: 0.0668 - acc: 0.981 - ETA: 1s - loss: 0.0658 - acc: 0.981 - ETA: 1s - loss: 0.0659 - acc: 0.981 - ETA: 1s - loss: 0.0657 - acc: 0.981 - ETA: 1s - loss: 0.0651 - acc: 0.981 - ETA: 1s - loss: 0.0651 - acc: 0.981 - ETA: 1s - loss: 0.0645 - acc: 0.981 - ETA: 1s - loss: 0.0645 - acc: 0.981 - ETA: 1s - loss: 0.0638 - acc: 0.981 - ETA: 1s - loss: 0.0633 - acc: 0.982 - ETA: 1s - loss: 0.0634 - acc: 0.982 - ETA: 1s - loss: 0.0633 - acc: 0.982 - ETA: 1s - loss: 0.0629 - acc: 0.982 - ETA: 1s - loss: 0.0628 - acc: 0.982 - ETA: 1s - loss: 0.0624 - acc: 0.982 - ETA: 1s - loss: 0.0621 - acc: 0.982 - ETA: 1s - loss: 0.0620 - acc: 0.982 - ETA: 1s - loss: 0.0617 - acc: 0.982 - ETA: 1s - loss: 0.0616 - acc: 0.982 - ETA: 1s - loss: 0.0619 - acc: 0.982 - ETA: 1s - loss: 0.0622 - acc: 0.982 - ETA: 0s - loss: 0.0634 - acc: 0.981 - ETA: 0s - loss: 0.0635 - acc: 0.981 - ETA: 0s - loss: 0.0628 - acc: 0.981 - ETA: 0s - loss: 0.0626 - acc: 0.982 - ETA: 0s - loss: 0.0627 - acc: 0.981 - ETA: 0s - loss: 0.0626 - acc: 0.981 - ETA: 0s - loss: 0.0626 - acc: 0.981 - ETA: 0s - loss: 0.0624 - acc: 0.982 - ETA: 0s - loss: 0.0622 - acc: 0.981 - ETA: 0s - loss: 0.0624 - acc: 0.981 - ETA: 0s - loss: 0.0634 - acc: 0.981 - ETA: 0s - loss: 0.0633 - acc: 0.981 - ETA: 0s - loss: 0.0638 - acc: 0.980 - ETA: 0s - loss: 0.0634 - acc: 0.980 - ETA: 0s - loss: 0.0634 - acc: 0.981 - ETA: 0s - loss: 0.0635 - acc: 0.980 - ETA: 0s - loss: 0.0634 - acc: 0.981 - ETA: 0s - loss: 0.0639 - acc: 0.981 - ETA: 0s - loss: 0.0640 - acc: 0.980 - ETA: 0s - loss: 0.0639 - acc: 0.980 - 3s 200us/sample - loss: 0.0642 - acc: 0.9808\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - ETA: 4s - loss: 0.0195 - acc: 1.000 - ETA: 2s - loss: 0.0770 - acc: 0.974 - ETA: 2s - loss: 0.0635 - acc: 0.981 - ETA: 3s - loss: 0.0621 - acc: 0.980 - ETA: 2s - loss: 0.0570 - acc: 0.982 - ETA: 2s - loss: 0.0528 - acc: 0.985 - ETA: 2s - loss: 0.0506 - acc: 0.984 - ETA: 2s - loss: 0.0527 - acc: 0.983 - ETA: 2s - loss: 0.0529 - acc: 0.983 - ETA: 2s - loss: 0.0518 - acc: 0.983 - ETA: 2s - loss: 0.0527 - acc: 0.983 - ETA: 2s - loss: 0.0523 - acc: 0.983 - ETA: 2s - loss: 0.0534 - acc: 0.982 - ETA: 2s - loss: 0.0506 - acc: 0.984 - ETA: 2s - loss: 0.0524 - acc: 0.984 - ETA: 2s - loss: 0.0510 - acc: 0.984 - ETA: 2s - loss: 0.0499 - acc: 0.984 - ETA: 2s - loss: 0.0506 - acc: 0.984 - ETA: 2s - loss: 0.0514 - acc: 0.983 - ETA: 2s - loss: 0.0538 - acc: 0.983 - ETA: 2s - loss: 0.0548 - acc: 0.983 - ETA: 2s - loss: 0.0540 - acc: 0.983 - ETA: 1s - loss: 0.0525 - acc: 0.984 - ETA: 1s - loss: 0.0509 - acc: 0.984 - ETA: 1s - loss: 0.0500 - acc: 0.985 - ETA: 1s - loss: 0.0497 - acc: 0.985 - ETA: 1s - loss: 0.0493 - acc: 0.985 - ETA: 1s - loss: 0.0493 - acc: 0.985 - ETA: 1s - loss: 0.0489 - acc: 0.985 - ETA: 1s - loss: 0.0483 - acc: 0.985 - ETA: 1s - loss: 0.0483 - acc: 0.985 - ETA: 1s - loss: 0.0481 - acc: 0.985 - ETA: 1s - loss: 0.0477 - acc: 0.985 - ETA: 1s - loss: 0.0467 - acc: 0.986 - ETA: 1s - loss: 0.0467 - acc: 0.986 - ETA: 1s - loss: 0.0461 - acc: 0.986 - ETA: 1s - loss: 0.0457 - acc: 0.986 - ETA: 1s - loss: 0.0456 - acc: 0.986 - ETA: 1s - loss: 0.0452 - acc: 0.986 - ETA: 1s - loss: 0.0459 - acc: 0.986 - ETA: 1s - loss: 0.0461 - acc: 0.985 - ETA: 1s - loss: 0.0465 - acc: 0.985 - ETA: 1s - loss: 0.0461 - acc: 0.986 - ETA: 0s - loss: 0.0458 - acc: 0.986 - ETA: 0s - loss: 0.0452 - acc: 0.986 - ETA: 0s - loss: 0.0451 - acc: 0.986 - ETA: 0s - loss: 0.0449 - acc: 0.986 - ETA: 0s - loss: 0.0448 - acc: 0.986 - ETA: 0s - loss: 0.0446 - acc: 0.986 - ETA: 0s - loss: 0.0447 - acc: 0.986 - ETA: 0s - loss: 0.0447 - acc: 0.986 - ETA: 0s - loss: 0.0446 - acc: 0.986 - ETA: 0s - loss: 0.0442 - acc: 0.986 - ETA: 0s - loss: 0.0443 - acc: 0.986 - ETA: 0s - loss: 0.0440 - acc: 0.986 - ETA: 0s - loss: 0.0446 - acc: 0.986 - ETA: 0s - loss: 0.0445 - acc: 0.986 - ETA: 0s - loss: 0.0445 - acc: 0.986 - ETA: 0s - loss: 0.0443 - acc: 0.986 - ETA: 0s - loss: 0.0447 - acc: 0.986 - ETA: 0s - loss: 0.0449 - acc: 0.986 - ETA: 0s - loss: 0.0447 - acc: 0.986 - ETA: 0s - loss: 0.0447 - acc: 0.986 - 3s 195us/sample - loss: 0.0446 - acc: 0.9861\n",
      "Epoch 5/5\n",
      "17000/17000 [==============================] - ETA: 5s - loss: 0.0053 - acc: 1.000 - ETA: 3s - loss: 0.0373 - acc: 0.989 - ETA: 3s - loss: 0.0321 - acc: 0.990 - ETA: 3s - loss: 0.0426 - acc: 0.988 - ETA: 3s - loss: 0.0389 - acc: 0.989 - ETA: 3s - loss: 0.0401 - acc: 0.988 - ETA: 3s - loss: 0.0395 - acc: 0.989 - ETA: 2s - loss: 0.0368 - acc: 0.989 - ETA: 3s - loss: 0.0346 - acc: 0.990 - ETA: 3s - loss: 0.0343 - acc: 0.990 - ETA: 3s - loss: 0.0330 - acc: 0.990 - ETA: 3s - loss: 0.0327 - acc: 0.990 - ETA: 3s - loss: 0.0355 - acc: 0.990 - ETA: 3s - loss: 0.0341 - acc: 0.990 - ETA: 3s - loss: 0.0329 - acc: 0.991 - ETA: 3s - loss: 0.0315 - acc: 0.991 - ETA: 3s - loss: 0.0301 - acc: 0.991 - ETA: 3s - loss: 0.0288 - acc: 0.992 - ETA: 3s - loss: 0.0280 - acc: 0.992 - ETA: 2s - loss: 0.0271 - acc: 0.993 - ETA: 2s - loss: 0.0262 - acc: 0.993 - ETA: 2s - loss: 0.0259 - acc: 0.993 - ETA: 2s - loss: 0.0286 - acc: 0.992 - ETA: 2s - loss: 0.0276 - acc: 0.993 - ETA: 2s - loss: 0.0284 - acc: 0.993 - ETA: 2s - loss: 0.0288 - acc: 0.992 - ETA: 2s - loss: 0.0284 - acc: 0.992 - ETA: 2s - loss: 0.0284 - acc: 0.992 - ETA: 2s - loss: 0.0296 - acc: 0.992 - ETA: 2s - loss: 0.0298 - acc: 0.992 - ETA: 2s - loss: 0.0293 - acc: 0.992 - ETA: 2s - loss: 0.0291 - acc: 0.992 - ETA: 2s - loss: 0.0287 - acc: 0.992 - ETA: 2s - loss: 0.0285 - acc: 0.992 - ETA: 2s - loss: 0.0284 - acc: 0.992 - ETA: 1s - loss: 0.0281 - acc: 0.992 - ETA: 1s - loss: 0.0278 - acc: 0.993 - ETA: 1s - loss: 0.0278 - acc: 0.992 - ETA: 1s - loss: 0.0277 - acc: 0.992 - ETA: 1s - loss: 0.0277 - acc: 0.992 - ETA: 1s - loss: 0.0278 - acc: 0.992 - ETA: 1s - loss: 0.0279 - acc: 0.992 - ETA: 1s - loss: 0.0283 - acc: 0.992 - ETA: 1s - loss: 0.0282 - acc: 0.992 - ETA: 1s - loss: 0.0283 - acc: 0.992 - ETA: 1s - loss: 0.0284 - acc: 0.992 - ETA: 1s - loss: 0.0281 - acc: 0.992 - ETA: 1s - loss: 0.0275 - acc: 0.992 - ETA: 1s - loss: 0.0276 - acc: 0.992 - ETA: 0s - loss: 0.0282 - acc: 0.992 - ETA: 0s - loss: 0.0285 - acc: 0.992 - ETA: 0s - loss: 0.0286 - acc: 0.992 - ETA: 0s - loss: 0.0293 - acc: 0.992 - ETA: 0s - loss: 0.0289 - acc: 0.992 - ETA: 0s - loss: 0.0288 - acc: 0.992 - ETA: 0s - loss: 0.0286 - acc: 0.992 - ETA: 0s - loss: 0.0283 - acc: 0.992 - ETA: 0s - loss: 0.0283 - acc: 0.992 - ETA: 0s - loss: 0.0285 - acc: 0.992 - ETA: 0s - loss: 0.0283 - acc: 0.992 - ETA: 0s - loss: 0.0285 - acc: 0.992 - ETA: 0s - loss: 0.0286 - acc: 0.992 - ETA: 0s - loss: 0.0287 - acc: 0.992 - ETA: 0s - loss: 0.0290 - acc: 0.992 - ETA: 0s - loss: 0.0289 - acc: 0.992 - 3s 204us/sample - loss: 0.0291 - acc: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20aa9147e10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "# reference here: https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to create link (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-f2adaa740cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use model.save() they say not to use pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# use this instead for keras, but it breaks???\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model_98.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    150\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             param_dset = optimizer_weights_group.create_dataset(\n\u001b[1;32m--> 152\u001b[1;33m                 name, val.shape, dtype=val.dtype)\n\u001b[0m\u001b[0;32m    153\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m               \u001b[1;31m# scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mdset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, name, obj)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHLObject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m                 \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSoftLink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.link\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to create link (name already exists)"
     ]
    }
   ],
   "source": [
    "# use model.save() they say not to use pickle\n",
    "# use this instead for keras, but it breaks???\n",
    "model.save('my_model_98.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,4)) # let's see what the images look like. quick sanity check\n",
    "for index, (image, label) in enumerate(zip(X_test[0:5], y_test[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (IMG_SIZE,IMG_SIZE)), cmap=plt.cm.gray)\n",
    "    plt.title('Test Img: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 1024)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape X and X_test  or we get errors\n",
    "X = X.reshape(X.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 1024)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       300\n",
      "           1       0.92      0.93      0.92       300\n",
      "           2       0.67      0.85      0.75       300\n",
      "           3       0.79      0.61      0.69       300\n",
      "           4       0.93      0.90      0.92       300\n",
      "           5       0.86      0.81      0.83       300\n",
      "           6       0.84      0.84      0.84       300\n",
      "           7       0.85      0.82      0.83       300\n",
      "           8       0.95      0.95      0.95       300\n",
      "           9       0.86      0.93      0.90       300\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      3000\n",
      "   macro avg       0.86      0.86      0.86      3000\n",
      "weighted avg       0.86      0.86      0.86      3000\n",
      "\n",
      "[[279   0   0   0   0   0   2   9   0  10]\n",
      " [  0 278   6   1   5   1   1   2   0   6]\n",
      " [  0   4 256  21   0   4   7   5   2   1]\n",
      " [  0   2  80 183   2  12   7   4   1   9]\n",
      " [  0   5   1   2 271   3   3   8   5   2]\n",
      " [  0   0  28  22   2 242   1   1   2   2]\n",
      " [  0   5  11   2   2  10 253  10   4   3]\n",
      " [ 17   0   0   0   2   5  20 245   1  10]\n",
      " [  1   0   1   1   3   6   2   0 285   1]\n",
      " [  0   9   0   1   3   0   5   3   0 279]]\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes Classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X,y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this\n",
    "filename = 'devnagari_naive_bayes_86.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       300\n",
      "           1       0.98      0.99      0.98       300\n",
      "           2       0.92      0.97      0.95       300\n",
      "           3       0.97      0.93      0.95       300\n",
      "           4       0.99      1.00      0.99       300\n",
      "           5       0.97      0.96      0.97       300\n",
      "           6       0.99      0.97      0.98       300\n",
      "           7       0.99      0.99      0.99       300\n",
      "           8       0.99      1.00      0.99       300\n",
      "           9       0.99      0.98      0.98       300\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3000\n",
      "   macro avg       0.98      0.98      0.98      3000\n",
      "weighted avg       0.98      0.98      0.98      3000\n",
      "\n",
      "[[298   0   0   0   0   0   0   0   2   0]\n",
      " [  0 297   0   0   2   0   0   0   1   0]\n",
      " [  0   2 291   4   0   2   1   0   0   0]\n",
      " [  0   1  15 278   0   4   0   0   0   2]\n",
      " [  0   0   0   0 299   0   0   0   0   1]\n",
      " [  0   0   5   5   1 289   0   0   0   0]\n",
      " [  0   2   3   0   1   1 290   2   0   1]\n",
      " [  1   0   0   0   0   1   0 297   1   0]\n",
      " [  0   0   0   0   0   0   0   0 300   0]\n",
      " [  0   2   1   0   0   0   1   2   0 294]]\n"
     ]
    }
   ],
   "source": [
    "# Knn- classification\n",
    "# k-Nearest Neighbor Classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X,y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this. this one takes a long time\n",
    "filename = 'devnagari_knn_98.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       300\n",
      "           1       0.93      0.90      0.92       300\n",
      "           2       0.76      0.81      0.79       300\n",
      "           3       0.81      0.76      0.78       300\n",
      "           4       0.94      0.90      0.92       300\n",
      "           5       0.87      0.80      0.83       300\n",
      "           6       0.78      0.82      0.80       300\n",
      "           7       0.88      0.91      0.90       300\n",
      "           8       0.89      0.90      0.89       300\n",
      "           9       0.88      0.91      0.90       300\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      3000\n",
      "   macro avg       0.87      0.87      0.87      3000\n",
      "weighted avg       0.87      0.87      0.87      3000\n",
      "\n",
      "[[281   0   0   1   0   0   3   9   2   4]\n",
      " [  3 270   4   0   1   0  12   0   4   6]\n",
      " [  1   1 244  18   1  13  14   1   4   3]\n",
      " [  0   4  32 229   2  12   6   6   3   6]\n",
      " [  2   0   1   4 269   4   6   2   6   6]\n",
      " [  0   2  14  15   7 239   5   8   7   3]\n",
      " [  2   5  13   8   3   6 247   7   6   3]\n",
      " [  7   2   0   3   3   0   9 273   1   2]\n",
      " [  4   0   8   2   1   0   8   3 270   4]\n",
      " [  1   6   4   4   0   2   6   1   2 274]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X,y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this\n",
    "filename = 'devnagari_decisiontree_87.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=10, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver = 'lbfgs',random_state=10)\n",
    "model.fit(X,y)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       300\n",
      "           1       0.98      0.99      0.99       300\n",
      "           2       0.85      0.88      0.86       300\n",
      "           3       0.91      0.84      0.88       300\n",
      "           4       0.97      0.97      0.97       300\n",
      "           5       0.96      0.95      0.95       300\n",
      "           6       0.93      0.94      0.93       300\n",
      "           7       0.96      0.96      0.96       300\n",
      "           8       0.98      0.99      0.98       300\n",
      "           9       0.97      0.96      0.96       300\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3000\n",
      "   macro avg       0.95      0.95      0.95      3000\n",
      "weighted avg       0.95      0.95      0.95      3000\n",
      "\n",
      "[[299   0   0   0   0   0   0   1   0   0]\n",
      " [  0 297   0   0   0   0   0   0   1   2]\n",
      " [  1   3 265  17   3   2   7   2   0   0]\n",
      " [  0   2  33 253   1   4   5   2   0   0]\n",
      " [  0   1   1   2 290   0   1   0   2   3]\n",
      " [  0   0   5   2   3 285   3   0   1   1]\n",
      " [  1   0   5   1   0   2 281   7   0   3]\n",
      " [  5   0   3   0   0   2   1 288   1   0]\n",
      " [  0   0   0   1   0   2   0   0 297   0]\n",
      " [  0   0   1   1   3   0   5   1   2 287]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "cm = metrics.confusion_matrix(expected, predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this\n",
    "filename = 'devnagari_logisticRegression_95.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do all steps ... misclassifications ... saving the best classifier model ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "model.predict(X_test[0].reshape(1,-1))\n",
    "yy = model.predict(X_test[0].reshape(1,-1))\n",
    "print(yy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for Multiple Observations (images) at Once\n",
    "model.predict(X_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on entire test data\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(y_test, predictions):\n",
    "    if label != predict: \n",
    "        misclassifiedIndexes.append(index)\n",
    "    index +=1\n",
    "print(\"Number of images misclassified: \",len(misclassifiedIndexes))\n",
    "print(misclassifiedIndexes[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rounded_probabilities(list1):\n",
    "    class_digit = 0\n",
    "    for x in list1:\n",
    "        y = round(x,2)\n",
    "        print(class_digit,\"==>\",y)\n",
    "        class_digit += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make probabilities on entire test data\n",
    "probabilities = model.predict_proba(X_test)\n",
    "print(len(probabilities))\n",
    "print(probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rounded_probabilities(probabilities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rounded_probabilities(probabilities[8])\n",
    "print(y_test[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_rounded_probabilities(probabilities[33])\n",
    "print(y_test[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(X_test[badIndex], (IMG_SIZE,IMG_SIZE)), cmap=plt.cm.gray)\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(predictions[badIndex], y_test[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[5:10]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(X_test[badIndex], (IMG_SIZE,IMG_SIZE)), cmap=plt.cm.gray)\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(predictions[badIndex], y_test[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best classifier is tensorflow\n",
    "# rerun and save to disk\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[2].reshape(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "\n",
    "filename = 'devnagari_tesnsorflow.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
